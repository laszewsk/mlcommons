# cloudMaskConfig.yml

# SciML-Bench
# Copyright Â© 2022 Scientific Machine Learning Research Group
# Scientific Computing Department, Rutherford Appleton Laboratory
# Science and Technology Facilities Council, UK.
# All rights reserved.

# This is a configuration file for the CloudMask benchmark.

# General info
benchmark: CloudMask
organisation: STFC
division: SciML
status: research
platform: nvidia gtx-2
accelerators_per_node: 16

# Training data
train_dir: /gpfs/alpine/gen150/proj-shared/jpdata/datasets/slstr_cloud/one-day

# Inference data
inference_dir: /gpfs/alpine/gen150/proj-shared/jpdata/datasets/slstr_cloud/ssts

# Model file
model_file: ./outputs-2/cloudModel.h5

# Output directory
#output_dir: /gpfs/alpine/gen150/proj-shared/jpdata/datasets/slstr_cloud/outputs
output_dir: ./outputs-2


# Log file for recording runtimes
log_file: ./outputs-2/cloudMask_Log


# Size of each patch to feed to the network
PATCH_SIZE: 256

# Original height of the image
IMAGE_H: 1200

# Original width of the image
IMAGE_W: 1500

# No. of channels
N_CHANNELS: 9

# Min allowable SST
MIN_SST: 273.15

# Amount to crop the edges of the images by
CROP_SIZE: 80

# Hyperparameters
seed: 1234

learning_rate: 0.001

epochs: 6 

batch_size: 128 

train_split: 0.8

clip_offset: 15

no_cache: False

nodes: 1

gpu: 2 



