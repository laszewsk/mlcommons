{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813ed198",
   "metadata": {},
   "source": [
    "# MLCommons Earthquake GPU Data Collection Notebook\n",
    "- Creates Pickle file with data for all available runs\n",
    "\n",
    "Please follow the instructions listed in README.md before running this notebook. This notebook should not be run while it stands in the analysis folder, but rather the results folder with the earthquake run data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1766bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:16.875744780Z",
     "start_time": "2023-09-01T16:13:16.598086634Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b1fd84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:17.933957876Z",
     "start_time": "2023-09-01T16:13:17.914189422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-01 12:13:17.912646\n"
     ]
    }
   ],
   "source": [
    "#get time\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb4edd",
   "metadata": {},
   "source": [
    "### Data Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed2d38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:19.667580309Z",
     "start_time": "2023-09-01T16:13:19.663883173Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_gpu_log(path):\n",
    "    \"\"\" Format the gpu data log into dataframe.\n",
    "\n",
    "    Args:\n",
    "        path: file path for the gpu log.\n",
    "    Returns:\n",
    "        dataframe with gpu data.\n",
    "    \"\"\"\n",
    "    # read in data\n",
    "    gpu_df = pd.read_csv(path, skiprows=1,header=None,low_memory=False)\n",
    "    \n",
    "    # get headers\n",
    "    header = gpu_df.loc[0]\n",
    "    header = header.str[2:].str.strip()\n",
    "    gpu_df = gpu_df.drop(index = [0]).reset_index(drop=True)\n",
    "    gpu_df= gpu_df.set_axis(header,axis=1,inplace=False)\n",
    "    \n",
    "    # set types\n",
    "    int_col = list(gpu_df.columns[1:-1])\n",
    "    gpu_df[int_col] = gpu_df[int_col].astype('int')\n",
    "    float_col = list(gpu_df.columns[-1:])\n",
    "    gpu_df[float_col] = gpu_df[float_col].astype('float')\n",
    "    time_col = list(gpu_df.columns[:1])[0]\n",
    "\n",
    "    gpu_df = gpu_df.groupby('time').mean().reset_index()\n",
    "    \n",
    "    return gpu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de6703ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:21.231877958Z",
     "start_time": "2023-09-01T16:13:21.226180758Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_timer_data(err_path):\n",
    "    \"\"\" Collect timer data from run output and create dataframe and csv.\n",
    "\n",
    "    Args:\n",
    "        path: file path for the run log.\n",
    "    Returns:\n",
    "        dataframe with timer data.\n",
    "    \"\"\"   \n",
    "    def index_containing_substring(the_list, substring, _not=False):\n",
    "        index = []\n",
    "        for i, s in enumerate(the_list):\n",
    "            if not _not:\n",
    "                if substring in s:\n",
    "                    index.append(i)\n",
    "            else:\n",
    "                if substring not in s:\n",
    "                    index.append(i)\n",
    "        if _not:\n",
    "            return index\n",
    "        elif substring == '# csv,RUN_STOP' or substring == '# csv,label3':\n",
    "            if len(index) < 2:\n",
    "                return -1\n",
    "            return index[-2] + 1\n",
    "        elif not index is None:\n",
    "            return index[-1]\n",
    "        return -1    \n",
    "\n",
    "    directory = err_path.rsplit(\"/\",1)[0]\n",
    "    output_path = os.path.join(directory,'timer.csv')\n",
    "    \n",
    "    # read in data\n",
    "    with open(err_path, 'r', encoding='cp850') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    success = any([True if 'Execution Complete' in x else False for x in content])\n",
    "    if not success:\n",
    "        print(f'Incomplete Run: {directory}')\n",
    "        return None\n",
    "\n",
    "    timerUpdate = any([True if 'RUN_STOP' in x else False for x in content])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    if timerUpdate:\n",
    "        # get timer content\n",
    "        start = index_containing_substring(content, '# csv,timer,status,time,sum,start,tag,msg,uname.node,user,uname.system,platform.version')\n",
    "        stop = index_containing_substring(content, '# csv,RUN_STOP')\n",
    "        if stop == -1:\n",
    "            print(f'Incomplete Run: {directory}')\n",
    "            return None\n",
    "        content = content[start:stop]\n",
    "        neg = index_containing_substring(content, '# csv', _not=True)\n",
    "\n",
    "        # fix for dictionary in csv\n",
    "        if not len(neg) == 0:\n",
    "            fixed = ''.join(content[min(neg):max(neg)+1]).strip().replace('\\n','').replace('\\s+','').replace('\\t+','')\n",
    "            for x in range(min(neg),max(neg)+1):\n",
    "                content.pop(min(neg))\n",
    "    else:\n",
    "        # get timer content\n",
    "        start = index_containing_substring(content, '# csv,timer,status,time,sum,start,tag,msg,uname.node,user,uname.system,platform.version')\n",
    "        stop = index_containing_substring(content, '# csv,RunTFTCustomVersion bestfit finalize VisualizeTFT event_num:0,ok,0.0,0.0,')\n",
    "        if stop == -1:\n",
    "            print(f'Incomplete Run: {directory}')\n",
    "            return None\n",
    "        content = content[start:stop]\n",
    "\n",
    "    # formatting\n",
    "    times = []\n",
    "    for x in content:\n",
    "        times.append(x.strip('\\n').replace('# csv,',''))\n",
    "    if timerUpdate:\n",
    "        if not len(neg) == 0:\n",
    "            times[min(neg)-1] = times[min(neg)-1]+fixed\n",
    "    data = []\n",
    "    for x in times:\n",
    "        x = re.sub(\"\\{[^}]*\\}\", lambda x:x.group(0).replace(',',';'), x)\n",
    "        data.append(x)\n",
    "\n",
    "    # save off data\n",
    "    df = pd.DataFrame(data)[0].str.split(',', expand=True)\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df[1:]\n",
    "\n",
    "    # convert to datetime\n",
    "    df['start'] = pd.to_datetime(df['start'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df = df[df['status'] != 'failed']\n",
    "\n",
    "    # get end time\n",
    "    # display(df)\n",
    "    # pprint(df.timer.unique())\n",
    "    for i, row in df.iterrows():\n",
    "        df.loc[i,'end'] = row['start'] + datetime.timedelta(seconds=float(row.time))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da49f39f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:21.992431751Z",
     "start_time": "2023-09-01T16:13:21.978885215Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_power_data(data_dict, gpu_df, timer_df):\n",
    "    \"\"\" Convert gpu dataframe into data for plots.\n",
    "    Args:\n",
    "        data_dict: dictionary of run data. \n",
    "        gpu_df: DataFrame with gpu usage data.\n",
    "        timer_df: DataFrame with event time data.\n",
    "    Returns:\n",
    "        dataframe with power data.\n",
    "    \"\"\"\n",
    "    # setup\n",
    "    data = {}\n",
    "    rename = {\n",
    "        '# time': 'time',\n",
    "        'id': 'id',\n",
    "        'gpu_util %': 'gpu_util',\n",
    "        'memory_util %': 'memory_util',\n",
    "        'encoder_util %': 'encoder_util',\n",
    "        'decoder_util %': 'decoder_util',\n",
    "        'gpu_temp C': 'gpu_temp',\n",
    "        'power_draw W': 'power_draw'\n",
    "    }\n",
    "\n",
    "    # collect run info\n",
    "    data['gpu'] = data_dict['run_info']['gpu']\n",
    "    data['numGpus'] = data_dict['run_info']['numGpus']\n",
    "    data['numCpus'] = data_dict['run_info']['numCpus']\n",
    "    data['mem'] = data_dict['run_info']['mem']\n",
    "    data['epochs'] = data_dict['run_info']['epochs']\n",
    "\n",
    "    # build power data total notebook\n",
    "    gpu_df = gpu_df.rename(columns=rename)\n",
    "    gpu_df['time'] = pd.to_datetime(gpu_df['time'].str.split(\".\").str[0],format='%Y-%m-%d:%H:%M:%S')\n",
    "    grouped = gpu_df.groupby(['time']).mean()['power_draw'].reset_index()\n",
    "    data['kWh_total'] = sum(grouped['power_draw'])*(1/3600)*(1/1000)\n",
    "    data = pd.DataFrame([data], columns=data.keys())\n",
    "\n",
    "    # build power data model fit\n",
    "    #gpu_df['time'] = pd.to_datetime(gpu_df['time'].str.split(\".\").str[0],format='%Y-%m-%d:%H:%M:%S')\n",
    "    delta = min(timer_df['start']) - min(grouped['time']).round('1h')\n",
    "    fit_event = timer_df.loc[timer_df['timer'] == 'RunTFTCustomVersion train timer_num:0']\n",
    "    fit_start = fit_event['start'] - delta\n",
    "    fit_end = fit_event['end'] - delta\n",
    "    fit_grouped = grouped[(grouped['time'] >= fit_start.values[0]) & (grouped['time'] <= fit_end.values[0])]\n",
    "    data['kWh_fit'] = sum(fit_grouped['power_draw'])*(1/3600)*(1/1000)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f510a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:22.915274922Z",
     "start_time": "2023-09-01T16:13:22.882313976Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_NNSE_data(err_path, run_info):\n",
    "    with open(err_path,'r', encoding='cp850') as f:\n",
    "        content = f.readlines()\n",
    "    content_df = pd.DataFrame(content).rename(columns={0:'string'})\n",
    "\n",
    "    indexes = content_df[content_df['string'].str.contains('NNSE \\n')].index\n",
    "\n",
    "    NNSE_df = pd.DataFrame()\n",
    "    for i in indexes:\n",
    "        data = {}\n",
    "        data['experiment'] = run_info['experiment']\n",
    "        data['gpu'] = run_info['gpu']\n",
    "        data['epochs'] = run_info['epochs']\n",
    "        NNSE_index = []\n",
    "        NNSE_index.append(i-1)\n",
    "        NNSE_index.append(i)\n",
    "        for x in range(1,6):\n",
    "            NNSE_index.append(i+x)\n",
    "        df = content_df.iloc[NNSE_index]\n",
    "        data['eval'] = df.iloc[0].values[0].strip()\n",
    "        data['time'] = df.iloc[2].values[0].strip()\n",
    "        data['averaged'] = float(df.iloc[3].values[0].split(' ')[-1].strip())\n",
    "        data['summed'] = float(df.iloc[5].values[0].split(' ')[-1].strip())\n",
    "        data = pd.DataFrame(data, index=[0])\n",
    "        NNSE_df = pd.concat([NNSE_df, data], ignore_index=True)\n",
    "    return NNSE_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4ab92",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8200c37f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:25.651895987Z",
     "start_time": "2023-09-01T16:13:25.606592193Z"
    }
   },
   "outputs": [],
   "source": [
    "# find run directories\n",
    "cwd = os.getcwd()\n",
    "directories = [os.path.join(cwd,x) for x in os.listdir(cwd) if os.path.isdir(x)]\n",
    "\n",
    "data_dict = {}\n",
    "for system in directories:\n",
    "    filesystems = [os.path.join(system,x) for x in os.listdir(system) if os.path.isdir(os.path.join(system,x))]\n",
    "    for filesystem in filesystems:\n",
    "        dates = [os.path.join(filesystem,x) for x in os.listdir(filesystem) if os.path.isdir(os.path.join(filesystem,x))]\n",
    "        for date in dates:\n",
    "            experiments = [os.path.join(date,x) for x in os.listdir(date) if os.path.isdir(os.path.join(date,x))]\n",
    "            for experiment in experiments:\n",
    "                if 'card_name' in experiment:\n",
    "                    # print(experiment)\n",
    "                    if '_output' in os.listdir(experiment):\n",
    "                        log_path = glob.glob(os.path.join(experiment,'*.err'))\n",
    "                        if not log_path:\n",
    "                            print(f\"Incomplete Run: {experiment}\")\n",
    "                            continue\n",
    "                        # print(log_path[0])\n",
    "\n",
    "                        timer_df = get_timer_data(log_path[0])\n",
    "                        if timer_df is None:\n",
    "                            print(f\"Incomplete Run: {experiment}\")\n",
    "                            continue\n",
    "                        experiment_path = experiment\n",
    "                        experiment = experiment.split('/')[-1]\n",
    "                        system = system.split('/')[-1].replace('-','_')\n",
    "                        filesystem = filesystem.split('/')[-1]\n",
    "                        date = date.split('/')[-1]\n",
    "                        #nsse_df = get_NNSE_data(log_path)\n",
    "                        experiment_name = f\"{experiment}.{system}.{filesystem}.{date}\"\n",
    "                        gpu_log = os.path.join(experiment_path,'gpu0.log')\n",
    "                        if os.path.exists(os.path.join(experiment_path,'gpu0.log')):\n",
    "                            gpu_log = os.path.join(experiment_path,'gpu0.log')\n",
    "                        elif os.path.exists(os.path.join(experiment_path,'gpu0.log')):\n",
    "                            gpu_log = os.path.join(experiment_path,'gpu0.log')\n",
    "                        else:\n",
    "                            print(f'Check path for GPU log for {experiment_path}')\n",
    "                            continue\n",
    "                        gpu_df = format_gpu_log(gpu_log)\n",
    "                        if gpu_df is None:\n",
    "                            continue\n",
    "                        data_dict[experiment_name] = {}\n",
    "\n",
    "                        if experiment.split('.')[-1].split('_')[2] == '1':\n",
    "                            gpu = 'a100'\n",
    "                        else:\n",
    "                            gpu = experiment.split('.')[-1].split('_')[2]\n",
    "\n",
    "                        # add run info to dictionary\n",
    "                        data_dict[experiment_name]['run_info'] = {\n",
    "                            'system': system,\n",
    "                            'filesystem': filesystem,\n",
    "                            'date': date,\n",
    "                            'gpu': gpu,\n",
    "                            'experiment': f\"{gpu}-{system}-{filesystem}-{date}\",\n",
    "                            'numGpus': experiment.split('.')[-1].split('_')[5],\n",
    "                            'numCpus': experiment.split('.')[-1].split('_')[8],\n",
    "                            'mem': experiment.split('.')[-1].split('_')[10],\n",
    "                            'epochs': experiment.split('.')[-1].split('_')[-1],\n",
    "                            'path': experiment_path,\n",
    "                        }\n",
    "\n",
    "                        # get power data\n",
    "                        power_df = get_power_data(data_dict[experiment_name], gpu_df, timer_df)\n",
    "                        # pprint(data_dict)\n",
    "                        # get NNSE data\n",
    "                        NNSE_df = get_NNSE_data(log_path[0], data_dict[experiment_name]['run_info'])\n",
    "\n",
    "                        # add DataFrames to dictionary\n",
    "                        data_dict[experiment_name]['gpu_df'] = gpu_df\n",
    "                        data_dict[experiment_name]['timer_df'] = timer_df\n",
    "                        data_dict[experiment_name]['power_df'] = power_df\n",
    "                        data_dict[experiment_name]['NNSE_df'] = NNSE_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4a925",
   "metadata": {},
   "source": [
    "### Get archived data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "832e55bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:28.354618951Z",
     "start_time": "2023-09-01T16:13:28.330849125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No archived data\n"
     ]
    }
   ],
   "source": [
    "archive = os.path.join(cwd,'rtx3090','archive')\n",
    "if os.path.exists(archive):\n",
    "    mar2022_df = pd.read_csv(os.path.join(archive,'mar2022_data.csv'))\n",
    "    for i, row in mar2022_df.iterrows():\n",
    "        row = row.rename({'Unnamed: 0':'experiment'})\n",
    "        row['experiment'] = f\"mar2022_{row['experiment']}\"\n",
    "        experiment = row['experiment']\n",
    "        if 'colab' not in row['experiment']:\n",
    "            system = 'rivanna'\n",
    "        else:\n",
    "            system = 'colab'\n",
    "        date, gpu, filesystem, epochs = row['experiment'].split('_')\n",
    "        experiment_name = f\"{experiment}.{system}.{filesystem}.{date}\"\n",
    "        #gpu = experiment_name.split('_')[1].lower()\n",
    "        # run info\n",
    "        data_dict[experiment_name] = {}\n",
    "        data_dict[experiment_name]['run_info'] = {\n",
    "            'system': system,\n",
    "            'filesystem': filesystem,\n",
    "            'date': date,\n",
    "            'gpu': gpu,\n",
    "            'experiment': f\"{gpu}-{system}-{filesystem}-{date}\",\n",
    "            'numGpus': 1,\n",
    "            'numCpus': 1,\n",
    "            'mem': np.nan,\n",
    "            'epochs': epochs,\n",
    "            'path': np.nan\n",
    "        }\n",
    "        # timer df\n",
    "        if not gpu == 'V100':\n",
    "            timer_df = row.drop(['experiment','__RunTFTCustomVersion bestfit']).to_frame().reset_index()\n",
    "        else:\n",
    "            timer_series = row.drop('experiment')\n",
    "            bestfit = row['__RunTFTCustomVersion bestfit']\n",
    "            timer_series = row.drop('__RunTFTCustomVersion bestfit')\n",
    "            row['RunTFTCustomVersion bestfit'] = bestfit\n",
    "            timer_df = row.to_frame().reset_index()\n",
    "        timer_df.columns = ['timer', 'time']\n",
    "\n",
    "        data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n",
    "        # no data available for gpu\n",
    "        data_dict[experiment_name]['gpu_df'] = None\n",
    "        data_dict[experiment_name]['power_df'] = None\n",
    "    \n",
    "    epoch2_table = pd.read_csv(os.path.join(archive,'epoch2_table.csv'))\n",
    "    for i, row in epoch2_table.iterrows():\n",
    "        gpu = row['experiment'].split('(')[0].lower()\n",
    "        system = row['experiment'].split('(')[1][0]\n",
    "        if system == 'r':\n",
    "            system = 'rivanna'\n",
    "            filesystem = 'rivanna'\n",
    "        elif system == 'R':\n",
    "            system = 'personal_pc_r'\n",
    "            filesystem = 'personal_pc_r'\n",
    "        elif system == 'G':\n",
    "            system = 'personal_pc_g'\n",
    "            filesystem = 'personal_pc_g'\n",
    "        elif system == 'L':\n",
    "            system = 'rivanna'\n",
    "            filesystem = 'localscratch'\n",
    "        elif system == 'c':\n",
    "            system = 'colab'\n",
    "            filesystem = 'colab'\n",
    "        experiment_name = f'mar2022_epoch2_{gpu}_{system}_{filesystem}.{system}.{filesystem}.mar2022'\n",
    "\n",
    "        # run info\n",
    "        data_dict[experiment_name] = {}\n",
    "        data_dict[experiment_name]['run_info'] = {\n",
    "            'system': system,\n",
    "            'filesystem': filesystem,\n",
    "            'date': 'mar2022',\n",
    "            'gpu': gpu,\n",
    "            'experiment': f\"{gpu}-{system}-{filesystem}-mar2022\",\n",
    "            'numGpus': 1,\n",
    "            'numCpus': 1,\n",
    "            'mem': np.nan,\n",
    "            'epochs': 2,\n",
    "            'path': np.nan\n",
    "        }\n",
    "        # timer df\n",
    "        timer_df = row.drop('experiment').to_frame().reset_index()\n",
    "        timer_df.columns = ['timer', 'time']\n",
    "\n",
    "        data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n",
    "        # no data available for gpu\n",
    "        data_dict[experiment_name]['gpu_df'] = None\n",
    "        data_dict[experiment_name]['power_df'] = None\n",
    "        \n",
    "    rtx3090 = pd.read_csv(os.path.join(archive,'rtx3090_data.csv'))\n",
    "    for i, row in rtx3090.iterrows():\n",
    "        row = row.drop('Unnamed: 0')\n",
    "        gpu = 'rtx3090'\n",
    "        system = 'personal_pc_g'\n",
    "        filesystem = 'personal_pc_g'\n",
    "        epochs = row['epochs']\n",
    "        experiment_name = f'mar2022_rtx3090_personal_{epochs}.{system}.{filesystem}.{date}'\n",
    "        # run info\n",
    "        data_dict[experiment_name] = {}\n",
    "        data_dict[experiment_name]['run_info'] = {\n",
    "            'system': system,\n",
    "            'filesystem': filesystem,\n",
    "            'date': 'mar2022',\n",
    "            'gpu': gpu,\n",
    "            'experiment': f\"{gpu}-{system}-{filesystem}-mar2022\",\n",
    "            'numGpus': 1,\n",
    "            'numCpus': 1,\n",
    "            'mem': np.nan,\n",
    "            'epochs': epochs,\n",
    "            'path': np.nan\n",
    "        }\n",
    "        timer_df = row.drop('epochs').to_frame().reset_index()\n",
    "        timer_df.columns = ['timer','time']\n",
    "        data_dict[experiment_name]['timer_df'] = timer_df\n",
    "\n",
    "        # no data available for gpu\n",
    "        data_dict[experiment_name]['gpu_df'] = None\n",
    "        data_dict[experiment_name]['power_df'] = None\n",
    "        \n",
    "\n",
    "else:\n",
    "    print('No archived data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc806cc7",
   "metadata": {},
   "source": [
    "### Create pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7a52cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T16:13:29.962430659Z",
     "start_time": "2023-09-01T16:13:29.954600043Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(cwd,'experiment_data.pkl')\n",
    "with open(pickle_file, 'wb') as f:\n",
    "    pickle.dump(data_dict, f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe944b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
